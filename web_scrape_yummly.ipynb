{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as urllib2\n",
    "import json\n",
    "import collections, itertools\n",
    "import requests\n",
    "import csv\n",
    "import requests\n",
    "import shutil\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install recipe_scrapers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recipe_scrapers import scrape_me\n",
    "def save_image_fn(dish, image_url, num):\n",
    "    #save image to file \n",
    "    resp = requests.get(image_url, stream=True)\n",
    "    if not os.path.exists(\"data/\" + dish):\n",
    "        os.makedirs(\"data/\" + dish)\n",
    "    local_file = open(\"data/\" + dish + \"/\" + str(num) + \"_fn.jpg\", 'wb')\n",
    "    resp.raw.decode_content = True\n",
    "    shutil.copyfileobj(resp.raw, local_file)\n",
    "    del resp\n",
    "    return\n",
    "\n",
    "def main_scrape(recipe_url_dict):\n",
    "    #Take food types from classes.txt and search AllRecipes for links\n",
    "    #Pagecount is how many pages to pull, each page has 25 results I think\n",
    "    global f\n",
    "    f = open('data/recipes_2.txt', 'w')\n",
    "    for food_class in recipe_url_dict.keys():\n",
    "        count = 0\n",
    "        dish = food_class\n",
    "        print(dish)\n",
    "        for rec in recipe_url_dict[dish]:\n",
    "            scraper = scrape_me(rec)\n",
    "            try:\n",
    "                nutrition_d = scraper.nutrients()\n",
    "                nutrition = []\n",
    "                for i in nutrition_d:\n",
    "                    ty = i.replace('Content', '').lower()\n",
    "                    \n",
    "                    va = nutrition_d[i].lower().replace('milli', 'm').replace('grams', 'g')\n",
    "                    if 'calories' in ty:\n",
    "                        nutrition.append(va)\n",
    "                    else:\n",
    "                        nutrition.append(ty+' '+va)\n",
    "            except:\n",
    "                print('no_nutr')\n",
    "                continue\n",
    "            ingredients = scraper.ingredients()\n",
    "            try:\n",
    "                img = scraper.image()\n",
    "                save_image_fn(dish, img, count)\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            result = \"|\".join([dish, rec, dish + \"/\" + str(count) + \"_fn.jpg\", f\"rating={'None'}\", str(nutrition), str(ingredients)]) + \"\\n\"\n",
    "            try:\n",
    "                f.write(result)\n",
    "                count+=1\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(result)\n",
    "                continue\n",
    "            print(count)\n",
    "            if count>20:\n",
    "                break\n",
    "    \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Queries for sparsely filled recipes\n",
    "search_dict = {'beef_tartare': 'https://www.yummly.com/recipes?q=steak%20tartare&sortBy=rel',\n",
    "'cheese_plate': 'https://www.yummly.com/recipes?q=cheese%20plate&sortBy=rel',\n",
    "'takoyaki': 'https://www.yummly.com/recipes?q=takoyaki&sortBy=rel',\n",
    "'beef_carpaccio': 'https://www.yummly.com/recipes?q=carpaccio&sortBy=rel',\n",
    "'sashimi': 'https://www.yummly.com/recipes?q=sashimi&sortBy=rel',\n",
    "'bibimbap': 'https://www.yummly.com/recipes?q=bibimbap&sortBy=rel',\n",
    "'escargots': 'https://www.yummly.com/recipes?q=escargots&sortBy=rel',\n",
    "'hamburger':    'https://www.yummly.com/recipes?q=hamburger&sortBy=rel',\n",
    "'fish_and_chips': 'https://www.yummly.com/recipes?q=fish%20and%20chips&sortBy=rel',\n",
    "'croque_madame': 'https://www.yummly.com/recipes?q=croque%20madame&sortBy=rel',\n",
    "'macarons': 'https://www.yummly.com/recipes?q=croque%20macarons&sortBy=rel',\n",
    "'tuna_tartare': 'https://www.yummly.com/recipes?q=tuna%20tartare&sortBy=rel',\n",
    "'gyoza': 'https://www.yummly.com/recipes?q=gyoza&sortBy=rel',\n",
    "'seaweed_salad': 'https://www.yummly.com/recipes?q=seaweed%20salad&sortBy=rel',\n",
    "'club_sandwich': 'https://www.yummly.com/recipes?q=club%20sandwich&sortBy=rel',\n",
    "'churros': 'https://www.yummly.com/recipes?q=churros&sortBy=rel',\n",
    "'poutine': 'https://www.yummly.com/recipes?q=poutine&sortBy=rel',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_url_dict = {}\n",
    "for i in search_dict:\n",
    "    url_list = []\n",
    "    scraper = scrape_me(search_dict[i])\n",
    "    for x in scraper.links():\n",
    "        if 'class' in x.keys():\n",
    "            if 'link-overlay' in x['class']:\n",
    "                url_list.append('https://www.yummly.com'+x['href'])\n",
    "    rec_url_dict[i] = url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_scrape(rec_url_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After the code above, Manually went through the images in each category and removed images that were not actually part of the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.path.isfile(path)\n",
    "file1 = open(\"data/recipes_2.txt\",\"r\")\n",
    "file2 = open('data/recipes_filtered_2.txt', 'w')\n",
    "for i in file1.readlines():\n",
    "    img_path = i.split('|')[2]\n",
    "    nutr = i.split('|')[4]\n",
    "\n",
    "    if os.path.isfile('data/'+img_path) and len(nutr)>5:\n",
    "        file2.write(i)\n",
    "    else:\n",
    "        pass\n",
    "file1.close()\n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"classes.txt\", \"r\")\n",
    "\n",
    "all_classes = file.readlines()\n",
    "class_counts = {}\n",
    "for i in all_classes:\n",
    "    j = i.replace('\\n', '')\n",
    "    class_counts[j]=0\n",
    "pics = open(\"data/recipes_filtered_all.txt\", 'r')\n",
    "all_pics = pics.readlines()\n",
    "for i in all_pics:\n",
    "    clas = i.split('|')[0]\n",
    "    class_counts[clas]+=1\n",
    "file.close()\n",
    "pics.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>hamburger</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beef_carpaccio</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cheese_plate</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>lobster_roll_sandwich</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>beignets</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cannoli</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>miso_soup</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>takoyaki</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>foie_gras</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>hot_dog</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>samosa</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>escargots</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>pho</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>caesar_salad</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>spaghetti_bolognese</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>omelette</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baklava</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>onion_rings</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>pizza</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>sashimi</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>frozen_yogurt</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bruschetta</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>creme_brulee</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>prime_rib</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beef_tartare</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>chocolate_mousse</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>oysters</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>dumplings</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>pulled_pork_sandwich</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple_pie</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>paella</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>mussels</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>lobster_bisque</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>ice_cream</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>greek_salad</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>croque_madame</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>breakfast_burrito</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>panna_cotta</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>tiramisu</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    class  count\n",
       "53              hamburger      5\n",
       "3          beef_carpaccio      8\n",
       "17           cheese_plate      9\n",
       "61  lobster_roll_sandwich     10\n",
       "6                beignets     10\n",
       "12                cannoli     11\n",
       "64              miso_soup     12\n",
       "97               takoyaki     12\n",
       "39              foie_gras     12\n",
       "55                hot_dog     13\n",
       "85                 samosa     13\n",
       "35              escargots     14\n",
       "75                    pho     14\n",
       "11           caesar_salad     14\n",
       "90    spaghetti_bolognese     15\n",
       "67               omelette     16\n",
       "2                 baklava     16\n",
       "68            onion_rings     17\n",
       "76                  pizza     17\n",
       "86                sashimi     17\n",
       "45          frozen_yogurt     17\n",
       "10             bruschetta     17\n",
       "27           creme_brulee     18\n",
       "79              prime_rib     18\n",
       "4            beef_tartare     18\n",
       "22       chocolate_mousse     18\n",
       "69                oysters     18\n",
       "32              dumplings     18\n",
       "80   pulled_pork_sandwich     18\n",
       "0               apple_pie     19\n",
       "71                 paella     19\n",
       "65                mussels     19\n",
       "60         lobster_bisque     19\n",
       "58              ice_cream     19\n",
       "48            greek_salad     19\n",
       "28          croque_madame     19\n",
       "9       breakfast_burrito     19\n",
       "73            panna_cotta     19\n",
       "98               tiramisu     19"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "count_df = pd.DataFrame({'class':class_counts.keys(), 'count':class_counts.values()})\n",
    "count_df[count_df['count']<20].sort_values(by='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
